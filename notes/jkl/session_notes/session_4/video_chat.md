jkl (he/they)
2:11 PM
1. What's the problem. 
2. Each presents their bit
jkl (he/they)
2:12 PM
multiple types of segments
Teja Sunku
2:17 PM
You're our Philosophy DM Liz
jkl (he/they)
2:17 PM
3. social media interjections
ryo
2:22 PM
https://notebooklm.google.com/notebook/1d269347-f686-4045-810f-fb7f6aa27a70
ryo
2:26 PM
https://finalspark.com/neuroplatform/
jkl (he/they)
2:28 PM
current agenda lol:
- listen to robots do our job for us
- talk about brain organoids and feel dread
- philosophy theories if there's time
üëç
üòÇ
‚ù§Ô∏è
Teja Sunku
2:31 PM
Should we interrupt if we have things to say?
jkl (he/they)
2:31 PM
yeah, we should pause when... hmm hand raise maybe
jkl (he/they)
2:35 PM
https://www.youtube.com/watch?v=fqnJcZiDMDo
ryo
2:40 PM
https://share.descript.com/view/Ox8Mvf6Rc6E
jkl (he/they)
2:54 PM
The Worst Idea Of All Time
jkl (he/they)
2:55 PM
1984 on controlling language
(just dropping alllll the mentioned links)
jkl (he/they)
3:01 PM
Supervenience!
jkl (he/they)
3:09 PM
o1 paper -- self preservation
jkl (he/they)
3:12 PM
scaling monosemanticity -- knowing when it's deceiving, recognizing when it's out of its own data set
ryo
3:14 PM
https://transformer-circuits.pub/2024/scaling-monosemanticity/#safety-relevant-deception
lizTheDeveloper (they/them)
3:14 PM
https://www.ai-transparency.org/
jkl (he/they)
3:18 PM
https://preview.goodfire.ai/
Teja Sunku
3:21 PM
Something something oedipal complex
Is AI killing us all truly the worst outcome?
Are there worse futures?
jkl (he/they)
3:23 PM
aidungeon
ryo
3:35 PM
I DDID SAY BVRB
jkl (he/they)
3:38 PM
Evolution in Four Dimensions
jkl (he/they)
3:41 PM
This is the larval phase of ai
the purpose of humanity lol

also plasmoids
