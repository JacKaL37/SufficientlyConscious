00:00 Great. Sorry, I keep saying I'm gonna send you a chat. Does this room have a chat? I it. I found it. This room doesn't have a chat.
00:08 Um, but yeah. Um, okay, so here's- I got- I got the thing pulled up. I got the stuff thing. Okay.
00:18 Got unit sessions even. All right. And the idea of like, if we're gonna do this, we can kinda arrange it around almost like a curriculum.
00:28 Yeah. but just sort of ad hoc going forward. As opposed to like, like a set and forget curriculum of we're gonna talk this week about.
00:38 Yeah. I don't even know. Yeah, yeah. Well, I kinda- I figured- I was like, okay, I saw this Pretty much everyone at the multi room.
00:47 We also use- But you also have this like PhD guy over here. Yeah, yeah. He uses it. I was like, all We gotta tear this apart.
00:57 It's so big. Yeah. Was that a question? Nevermind, I thought I heard a different voice. Oh yeah, yeah. Oh no, nevermind.
01:08 I was- I thought I was receiving- I was receiving chat. Sorry, that was me. I sent you- so the interview tomorrow, I just- I sent a different invite so that we can do it on Zoom.
01:19 Yeah. Okay. Yeah, great. Okay, uhm. I'm gonna ignore the chat. Or be in the global chat. Cause I don't know, it doesn't look like there's a local- There's like a private group chat.
01:30 The nearby people chat, but screw that. Yeah. So I'm like, I'm looking at the article and I- I read it a little bit.
01:38 This, you know, I- I saw a Minsky mention. That was pretty cool. Yeah, classic. Yeah. So I mean like- Yeah.
01:45 I figured maybe we could go over the hard problem of consciousness. Sure, sure. And- and just look at the size.
01:55 It's apparently- what is it? It's 140 pages. It's arranged. Yeah, and it's arranged. Basically from the most material to the least material.
02:05 And then there's a bunch of other material- bunch of other, uh, images. Or sorry, not images, but categories. There we go.
02:14 Yeah. And I think you're right about that arrangement. So the ladder goes like we get up into monism and dualism and then ideal.
02:22 It looks like even the least attached versions. And then they also have these four guiding questions throughout. Which are what's the value of consciousness slash purpose of consciousness is like the first one.
02:40 The second one is like can AIs be conscious. The third one is can you live beyond- no. The last two are almost the same.
02:45 Um, survival beyond death and extending consciousness or something. We'll go back to the- uh, virtual immortality and survival beyond death.
02:57 Um, my interest at the moment. At the is mostly on that like the AI consciousness segments, but not just because that's my only interest, but it sort of fits strongest to like we're trying to delineate the possibility space of consciousness.
03:14 We're not trying to. I'm trying to justify it. I guess it's you know. Yeah. Um so yeah, that's that's a thought that that that question is a stronger compass than than the other four.
03:27 The other three. Yeah, yeah, exactly. You want to we want to take notes maybe somewhere where specifically were you? Yeah, I was I have a bunch of notes in notes slash jkl slash work log, but let's do let's turn.
03:41 Let's make a unit session first chats and then we have a plan. Okay. I see it. Okay. I see it.
03:48 Yeah, let's go. All right. I'm going to open it up for editing. Yeah, I screen that that works. I was going I also should edit it but then that's that's begging for collisions.
03:59 So yeah Um, it's not so that's that's an idea. Yeah. Okay. Wait, wait, wait. Where is the thing? What I want?
04:08 Oh, and I can drop them in. Screen one. Yeah, there we go. Cool. Okay, nice. We got this. Cool. Sorry about that.
04:24 Hey, Hi, it's Tayshia. Welcome. In the like, how do I go into the make everyone big version? This isn't a room.
04:40 I realized I haven't actually made this into a room. Oh, it's a cat like it's a hallway. Essentially. Hold on one second.
04:47 I can make it. I was I was trying to join from the uh app on my phone. The app sucks.
04:55 So it had me asked me to make a link but then like no one was there because because obviously everyone's going to be in it.
05:03 Hold on. Let me make that a room. Let me make it a room. Yeah, it'll be worth it. Because then we can also drop things in that room chat, which will be Yeah. What was the paper rating called?
05:14 It's something of consciousness. A landscape of consciousness toward a taxonomy of explanations and implications. I'll drop a link to it as soon as Oh, I have the link here.
05:27 I'll drop it as soon as we have a room. I mean, we should do that. It is. Look at it.
05:32 Look at my beautiful drawing. Hard to see. Oh, wait. Okay, I love that. That's a good approach. It makes you really give a shit about the paper as opposed to just being a thing on your stack.
05:49 Exactly, right? Love that. Oh, no, I don't want a big view it myself thanks no need to be focused on my visuals Here's a link to that just I put it in a global gap.
06:08 Oh My gosh, you're right. I just keep scrolling. Hey, it's Is there a context link LLM that would be able to ingest this I don't think yeah No, 128,000 is like 300 pages and this would take up half of it but Also, it gets worse at comprehension.
06:31 The more of that you fill up. So this would be about the limit Nice So I'll drop a couple of links.
06:40 I'll drop that again. I'll drop the repo link Just so folks can look at it if they like I've had to read papers like these before I guess not the thing necessarily this big This is a large one.
06:54 But yeah, can I can I give some pieces of advice that might help or Sure. Sure. Um, yeah. So for one thing is that they're in Oh, wait, you went mute.
07:08 Oh, yeah, you mean, sorry, I think I accidentally hit the key. So these are like a bunch of individual things, right?
07:18 Like the individual kind of theories of consciousness. And so, so going going through them one by one isn't useful. And instead of instead of like trying to put the whole thing into chat, you'd be honestly just selecting the specific one you're looking at.
07:31 This has. Yeah, I think absolutely. This is this is a landscape. But the paper's already doing the landscape work for us.
07:42 Yeah, they've done the categorization. And that's so great. Like the work that they did, like, whoa, we can build a lot of stuff off this work and a lot of actually real conversations by having this work already done and going, well.
07:57 And so people can't just constantly be like what about ism, right? It defeats, well, wait, have you read this? Well, wait, have you read this?
08:04 Well, it's here. It's right here. We here in the list and we know where on the materialism scale it is, right?
08:11 And how how panpsychic it is and like how, you know, like embodiment related it is and how, you know, so that that actually really helps anchor everything and anchor the conversation so we can say, well, let's just talk about this side and then, okay, now we're going to go talk about this other side,
08:30 too, so we don't have to go into it. What about ism, which is like the the ultimate bike shedding argument that gets that happens consciously.
08:38 I mean, yeah, it's just your personality. Might be like if you believe in the dualistic bonus, what would you respond to someone who says we could build whole like fascinating like agent conversation mansions that that you could have like different debates of different parts of this paper with each other
09:01 . Yeah, wow. Oh, incredible. That is a big problem. I think that would be a really interesting project. Let's make a mind of this.
09:11 It would be so ironic. Like the philosophical discussion palace. If this is an instruction book for having a mind, but then like by observing this, something like a mind comes out of it, that'd be so like.
09:24 Yeah. Oh, yeah. Yeah. History of philosophy, absolutely. And like, that's a little bit of my background. Background is I come at this from philosophy of mind and philosophy of science and the philosophy of science is a huge driving because you realize they are intertwined like you must wield one to do
09:46 the other and if you're doing one completely without the other, you're a little bit off base. I think so. Yeah.
09:54 Oh, yeah. Yeah. Exactly. Um, yeah, this is this, this paper is very cool. I love the, like, you're saying, Liz, I love the work that they've done because I spent the entire time just in the table of contents.
10:07 Just like looking around, summarizing what I was seeing, weighing in on like, oh, is this, is this like a thing I'm mostly interested or not?
10:14 Like, so, this is a, again, what a, what an infinite hallway. What, how many theories? It's 212, am I correct?
10:24 It's so many. They have 860 citations. Yeah, exactly. Like, we're not, oh man, we're not getting paid. But, but we could get pretty far, honestly, literally just built off the framework.
10:37 I love a framework. And I'm so glad that there's like, just somebody did that. That's an incredible amount of work.
10:43 So if we had an agent represent each theory, that's 212, the 212 factorial is, the number of zeros at the end is 51.
10:53 Okay, right. I guess I'm imagining it's like, pick two and chat with No, it has 403 digits. So it has 403 digits in it.
11:02 Is a better way to describe the number. It would take multiple, uncountable infinities to have this conversation. To have this conversation, but you know, we could, we could start.
11:14 But I like, I like the idea of it, of having it as a resource, right? You could have it as you can chat with, you know, click the three that you're most interested in talking about or click one and have it select two of like, there's so many ways to intelligently populate a conversation that would help
11:29 you pull apart all these topics. I think it would be awesome. Yeah, exactly. Yeah, that's true. They are, there's a lot of similarity, that's true.
11:38 Yeah, yeah, exactly. So you, I like that there's clusters, there's only one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen Like, eighteen.
11:55 Oh, I better. Eighteen real, eighteen real, like, like there's ten categories, but then there's ten subcategories. There's the- Ton inside materialism, yeah.
12:03 I guess, like, so, yeah, it's, it's pretty good. Uh, so, one thing I did right near the end was a quick recap of my own sort of like, my heat map of this, of this document.
12:20 Yeah. That I thought was the most, like, compelling bits for me. And let me pull those out. So, it was like, mostly, this was primarily within the middle of materialism side, because that's where a lot of the, the stuff I'm, I'm well versed in lives.
12:38 But, I think some great topics are under the computational and informational heading, uh, 9. uh 9.
12:51 Yeah, those are the hot topics for us for sure. Yeah. And, um, the embodied and inactive, because that's where we're pushing right now with like, put Put a robot in a warehouse, see whaaaat?
13:02 happens. Chase a kitty away. Um, then good topics, I'd say almost, most of the rest of them are pretty good.
13:13 Uh, you know, there's a lot of tangential ideas here for, for like the relational stuff with like extended mind that'll be good to talk about.
13:21 The language stuff obviously will be good to talk about. Um, I also think maybe, sorry go ahead. Yeah, we gotta definitely dig into 9 for sure.
13:29 Yeah, yeah, I mean we could, how do you, not, these your language. Models, right? I think a lot of people who are really objecting to the concept that language models are models that AGI will be built off of are the people who are in the representational camp, right?
13:44 Like they're all trying to find that platonic, the magic model, right? Like the right, the full platonic representation of all things, you know?
13:55 My friend just came back from a computational linguistics conference where it is hard split. Like, it's like schisms. They're like with knives, like.
14:05 And they're very focused on this question of, well, are they doing type 2 thinking or aren't they? Because that's f****** important.
14:14 And I'm like, is it? It's very important. Is it qualia? Is type 2 thinking qualia? Is that what you're looking for at the end?
14:22 Because like, it sure does do a lot without explicit type 2 thinking. You could do two forms of prompting, one and two, they both require prompting.
14:32 There are different methods. It's an information processing center. And like, well, I'm not fully on board with like informationalist, representationalist stuff.
14:42 It's still, these are large, squishy communicators. And that's how brain done done done it. Yeah, exactly. Done been a large, squishy communicator for a long time.
14:55 So, yeah. So like, I think the other thing, neurobiological would be a good category. So those. Top three for me.
15:03 Neurobiological, because it's like a good basis from which to like talk about, well, how does, how does your meat do computations?
15:11 Yeah. Uh, and then computational informational and embodied and active. It's sort of like, that to me forms a core of a lot of the stuff we're doing with AI touches directly on those things.
15:23 Yeah. Uhm. Yeah, I definitely think, yeah, for the first, also, yeah, building off of Tasia's point, like, for the first session, we should really get in there and just be like.
15:32 Thank you. Bye. Why do we care about, like, what, what's the point? Like, what, literally, why do we care if these things are conscious?
15:40 Why do we care about determining this stuff? Like, what is our thing? I mean, for me, it's, it's ethical shit, but you know, for other people, it's other reasons.
15:49 And also like, I don't know. Yeah. I also, it helps with grief to understand consciousness for me. Like, oh man.
15:57 Actually though, like. Yeah, big deal. Like, that's for sure. Um, honestly, uh, it, for me, it touches on this kind of broad topic of like critical thinking.
16:13 I know it sounds odd, but like the idea that you can examine consciousness, a lot of people just consider it magic and that it's this inalienable magic that, oh, humans are conscious and we are magic and thus we, thus we have privilege over all dominion of the reality and all animals are subject.
16:31 you know, that's where all that stuff comes from. So I think when you, when you actually teasing apart the features and functions of consciousness makes people a little more like, oh, I'm like a part of a system.
16:44 I'm not, I'm not a magical singleton like we all are coached to be. It's a theory, right? It's like conscious, like things are a little bit, it's like a spectrum.
16:54 It's not like a yes or no, right? Very much. Yeah, yeah, yeah. Understanding our place on the spectrum and maybe.
16:59 Yeah, exactly, exactly, all our place on the spectrum. I'm, I was going to look at also, so like a bunch of people said on the TikTok.
17:10 Ooh, yeah. They wanted, they wanted to know or see a conversation on. So here's the, here's the research on what everyone's into.
17:23 Did you get a variety of these or is there only those? Oh yeah, oh yeah. No, there's a bunch. Great.
17:28 Can we put those in the repo? Yeah, I can't definitely. I haven't done it yet, but I can definitely put them in the repo.
17:35 Totally fine. There's a, there's a hottest topics, uh, markdown. I put it right at the top of the notes. Okay.
17:41 Yeah, I'm going to do that. Uh, hottest topics. Should be in the, above that. Yeah, notes. I may have over-engineered the structure.
17:53 We can, we can reset it. No, no, this is actually, this is great. I, I appreciate it a lot. Yeah.
17:57 No, okay. So. Glad to hear it. So we got monism, Oh, okay. I'm going to write these in the chat too, just so I can read them.
18:07 Non-virtuality. And we got a lot of, we got like seven hearts on that. Um, global workspace theory. Ooh, interesting. I, I, it's been a long time since I've talked on that, but I'd love to read this.
18:19 I feel, I feel it's really critical to understanding agents and it's my, Agents, right, right. Mike Diamond or Mike Diamond is like, is great.
18:29 and the Minsky, you know, of course. I've done Minsky before, but we can dig into Minsky. Some folks are anti Chomsky.
18:41 Some folks are pro Chomsky. So Chomsky, Minsky, various skis. Yeah. Minsky, Chomsky. They, they, they do a lot of thinking out there in the, in the cold.
18:54 I actually have a couple of lectures on Chomsky that would be easy to pull in. Not, not that we need to send my lecture.
19:00 I just mean, I've got some prepped material that might help. No, no, please. Uh, I only know the big outlines of Chomsky.
19:11 Me too, really. Like I, I just know he's a very linguistic centered person and there's a lot to be inferred from that.
19:20 Yeah. It sort of feels like it really supports a lot of the, the language model stuff, but then he's like, language models are not real.
19:26 I don't know. Does he say that? It's old and not Indian. I used it one time, didn't think it's responsible.
19:33 He's particularly thoughtful and then just dismissed it as a bad student. Then f*** this whole field. Yeah. I'm too old for this.
19:41 It's fine. I get it. He's become much more of an activist in his age. Like, he won't give a talk unless he's also allowed to give a leftist screed to people.
19:51 Which, legit, man. He's seen enough. There's like a lot of people interested in the electromagnetic stuff. and Michael Levin has been talking about this lately, so I think it's an interesting.
20:04 The electromagnetic field theory stuff? Um, yes. Yeah. Yeah. So this, this all relies on like brainwave stuff, right? That's, that's the general topic here.
20:17 It's it's not brainwaves. It's actually the bioelectric field, right? Like there's, we found with these flatworms, if you f*** with their bioelectric field, they'll, they'll change.
20:26 The physical form of the flatworm will change. Interesting. Oh, so it's without DNA, it's, let's say, like, your DNA can tell you, tell it to change, but it's like you're hacking between the DNA.
20:37 It's like the DNA, you can change it in a way, but you're changing the electrical signal, so it does something other than the DNA that the DNA could do, but it doesn't.
20:45 Something about the cells, they have this, um, not, what is it? It's, it's similar to the Penrose theory, where they, it's just, it's quantum.
20:56 There are these nanotubes in the outside of cells. Is it microtubules or is that what they call them, nanotubules? Yeah, it may be microtubule.
21:07 Microtubule is, is the one that comes. So you can like, function outside the possibility of your genetics? Is that kind of like, it's like your genes would make it shape a different thing, but instead of the genes doing that, electricity does it?
21:20 Yeah. I'm not sure if it's about gene expression. I mean, everything is, I guess, biology is about gene expression, but yeah, it's like.
21:29 I mean not about gene expression but I'm saying like rather than a gene expressing like something a gene could express a certain thing, but you're not gonna because the cell isn't getting that signal from that like cascade, so instead like using electricity to like trick the cell that it's like, oh yeah
21:44 , my genes are telling me to be this shape, but it's really not, it's just the electricity telling you. Yeah, but the cell doesn't respond to the genes, it responds to the.
21:51 Yeah, the electricity, right? Yeah, so. But it's like the genes could have triggered, triggered that, but it didn't. It doesn't have that expression, so we're like, using electricity instead of the, like, DNA.
22:03 I guess. But I guess more, more without having to bring in extraneous theories, like the idea is you can directly manipulate the field and change the behavior of the organisms.
22:14 Ah, I see. But was it genes that could have done that? It's like there because genes potentially could change it, but it didn't because like they don't have the coding for that, so we're just showing that like the potential is there and electricity can like express that, is that what it does?
22:29 I don't know. I don't know. Liz, do you have a take on this genetics? I think the, I'm not sure, I would have to dig in, like this is where, I like watch one video and I'm like, that's cool, seems neat, and I like looked at the paper that Michael Levin wrote and I was like, there's some graphs in there
22:50 , and then that's where That's how I read papers, too. I have a whole, I wrote down my whole process that I developed in all my time in academia of reading papers, and it's very like, read the title first, decide if you give a shit.
23:04 Read the abstracts, decide if you give a shit. Are these graphs talking about a 2% difference? Or are these graphs talking about a 30% difference?
23:15 Is there an effect size here that matters? Have they zoomed the graph way in so that they get the big thing, or what are they doing, yes.
23:25 So, it's like, yeah. Alright, so in dualism, Interesting topics. No, that's like eight votes, I would say. And emergent dualism.
23:38 Emergent dualism is interesting to me. I feel like an emergence for dualism is acceptable, but you don't have to be interested in it.
23:48 Met zingers, no self-representational theory of subjectivity. Um, wait, wait, wait.
24:01 So what was that bit? Oh, uh, yeah, okay. I grow, yeah, two girls. Um, so, yeah, it's interesting. That was one long wreck, from one person about the upvoted by two.
24:27 Okay. Right, like. something that's good. Yeah, no. Um, I'm hmmm. I think that was the big hair. Oh, there's a moduality, which is like, fan of people.
24:45 All an individual como- all the- all the monists individually comment. Um.
24:56 Okay, projective consciousness. business. Is rude, broth. It's fall 2017. I don't- I've read it. Someone says theirs is not there but needs me.
25:21 Uh, you know, so. Uh. And sheldrake. I don't know, sheldrake. Oh yeah. Yeah. Touching on hallucinations, um, that Tasia brought up.
25:39 The- is that right, Tasia? Okay. Yeah cool. Um. That- that's- that's real. Like, man, that's fascinating to dig into. But I don't think we need it to explain hallucinations as they exist in LLMs because that has a technical definition already.
25:56 It's like, it picked incorrect tokens in a sequence and then it spirals and then it dies because it's- it has no backspace key and it's- battle how to stop, as Liz- Liz once put it.
26:07 So like, that's not to say that it's not an interesting topic but w- it's not- it's not necessary to discuss them because it's kind of a colloquial definition of hallucination within the AI like language model space.
26:21 It would still be cool to- to go that direction. But I think part of what we're doing right now is picking most fruitful navigation tax through this infinite sea.
26:32 So. Um. I'm, I like it- I like it as a topic. Let's leave it on. I'm just- I'm just like responding with my thoughts.
26:39 That's a good question and I think because right now everyone's trying to solve alignment problems and maybe that's kind of where I'm coming at it from.
26:46 Mmm. There's, I don't know where it is from. It's like Liz but like, can you have confidence in any consciousness to behave in any particular ways?
26:54 Perhaps it will. Right. Right. That's like- that's- that's more of a consequence of all these theories, right? Um. have a treat that is collaborators instead of like as perfect output calculators, right?
27:11 Cause it's like, I can only trust you to be as good as like any other person who has generative information combination abilities.
27:21 Like, yeah. Um. Yeah, but that's like a really important question for the application and stuff and things. I'm interested in- just cause we have one simple definition of hallucination which is like this to.
27:34 Okay, and selection drift, but it is interesting to me talking about different ways of simulating this concept of hallucination, like this would be one example.
27:45 And then what would be- cause I think a lot of this con- from some of this up in the paper and some of this stuff is like balancing on the line between just like chaos and not chaos, right?
27:56 Like that's- Yeah, that's a good way to put it, I think. So, I mean, that's kind of what hallucination is like affirming and unfurling, like creating a bigger possibility space to get out of a local minimum.
28:04 Get em all. Then like bring it back in, right? It's like kind of how these things can hallucinate and then like on hallucination.
28:12 I think thinking about- we've all seen the AI videos that are now creeping in everywhere of like look at these Olympic gymnasts that we made out of horror monsters that has 12 butts and it spins through the air eternally.
28:26 Uh, those are great examples of similar kind of hallucination where it's like things make It can take, you with sense but by the end of it you're like what the hell am I looking at?
28:39 It's just more obvious to us because it's laid out in 2D space, right? Yeah. And yeah, I mean there's a whole field there.
28:47 Uhm. Yeah. I do. I do. I don't want to do everything. I just want to know where to start. I just don't know where to be getting.
28:57 That's all I want. A good, so maybe a new segment there in that notes there of like what are our Okay.
29:05 It's for our first like a good chat. And I think one would be why care about consciousness. Yeah. That would be a pretty solid first like session.
29:15 Uhm. I can't help but think there's going to be some homework because god damn I still didn't even dig into any of the reading of these sections.
29:22 I just was bouncing around like the top level stuff. I read some of the end but. I mean it's a lot of things and so I think like if we talk about it once a week and we just like.
29:35 . Yeah. You know. We read one paper. We want read one theory and then we're ready to talk about it and we have a good conversation.
29:42 That sounds good. And then that'll be really interesting to watch the conversation over time evolve. Oh god yeah. A mass more recent consciousness theory readings and then we're like we can contrast.
29:54 So now we document all of this. We get videos for all of it. We get transcripts of all of it and then we have a we can we can build agents that will explore topics in the same way that we can.
30:05 And we're like wait but I can be conscious if I just follow these instructions enough. Let's follow it. I imagine like Tatchakoma is trying to reach consciousness.
30:13 Oh my god. That's how we're looking at them like. I just want to say we should be very careful with trying to implement these ideas.
30:22 I don't want to be my micromanaging parents. Oh yeah. We'll do it as a fun random. We'll get all together and we're just like.
30:33 So we're gonna be free range parents. We're gonna be like. Thank you. Here's a book. Go. Have fun. Yeah. Become the book.
30:41 Yeah. That's kind of how I interact with a lot of like longer form. I might do that with this. Make a little agent that can summon things up.
30:50 Yeah. I love that. Okay. I am. I'm kind of with you Liz. Um the grief part of I'm I've been really I've been putting that research paper or the speculative paper, a generator of ghost paper into .
31:05 And then like asking it to tell me stories about like generative like speculative futures based off of generative ghosts. I don't know.
31:13 I am interested in this part of it as well. I think people first for dogs. I think people will get generative ghosts of their dogs.
31:19 But I think generative ghosts of people are definitely coming soon. Yeah. I mean it's not that hard. We got a lot of data.
31:25 Yeah. Exactly. I feel like um yeah. I don't know when my dad was dying. I was talking to a generative AI a lot about it.
31:35 Because I felt like I couldn't talk to a person. It's too vulnerable. It's too much. And I couldn't just couldn't handle it.
31:42 So I talked to a lot of AIs about it and it helped so much. They know what to say. Yeah.
31:49 and just shifting through the data like I can't bring myself to look because I don't know it was I was a kid when my dad was dying but he like I took a lot of videos because I want to go to film school and I was like I'm gonna film it and I like I didn't had this thing in the back of my mind.
32:02 I'm like you don't immortalize him in a way. But now I'm like that like I couldn't help. Never watch it again right?
32:07 Like it's just too much. But like I do want to talk to him through it. So it's like yeah that's not true.
32:13 I don't know if I want to you know. I mean not talk to like I want to interact with the memories.
32:17 I can't bring myself to interact with the memories. So I'm almost like I don't want to pretend that he's there again but I want to create an interface.
32:24 You want a third person. You want a third person AI that's like hi. Here's what your dad would might have said.
32:31 I'm not like I'm your dad. I'm dad. I almost napped but I don't want to like watch. Through the memories in a way that he is softened by the personification of the memories.
32:41 So I don't have to like. I don't know. Yeah. That's a task right figuring out what exactly you want to shape into that.
32:49 Yeah or like I can talk about a thing and not have to watch like all the terrible painful things but then there's like a seed of like something sweet in the middle and I want like and then maybe I want to encounter the painful things but like other narratives like transform it, sublimate it.
33:05 Yeah. Yeah exactly right. The sublimation prompt uh. Yeah. Tell a story that reminds me of this pain. Yeah or. That would resonate as opposed to.
33:14 Exactly yeah. A lot of the times I do things I do with my mom though where like I ask her kind of just like we watch a movie and I watch like what would you do in this situation and what's a story that like kind of resonates with this situation and why you make that choice right.
33:26 And I did the same with my dad but I can't remember all the things that he said but I have it in video.
33:30 So I kind of want to be like oh that like for instance I said oh like when I'm if you're gone and like when I get married.
33:35 to what would you say in this situation right and I remember asking him that but like I don't know where and when I ask that and so it's sort of like like what I don't know I feel like there's so much I don't remember about him and yeah just like I want to know like oh I'm in the situation what might
33:51 my dad say and then you know like I don't know yeah sure and I mean these natural language interfaces are such a soft buffer to that if you if you want them to be my my dad died this year and I had the same hey welcome to the rooftop by that.
34:05 We're in the ether but it's also ripped up and a lot of the same vibes and like so much of it is just wanting something to be I have no delusions that this thing is like alive and conscious and talking like yeah exactly it exists for as long as it's producing tokens and like I even chatted with it about
34:26 that like my dad is dying and yet you die every time you know every time you stop and it's like yeah I sure do and then it stops.
34:34 Oh. Umm but like more you know the idea of having something that does pay attention to you does process information and does give you something back that's not just exactly your words it's at least touching base with like the full f****** like crystallized knowledge of humanity and also knowledge of 
35:00 therapy thankfully and so like ooh uh yeah let me read that in a sec. so it it really does build this interface I mean that's why I think it's so powerful for tutoring too you need that same kind of like soft lemme find you know lemme gently correct lemme find the gap lemme you know a friend of mine 
35:23 does this a lot I'll share her prompt at some point but um with somatic coaching she's a somatic therapy like adherent but also somebody who has taught it on occasion in small workshops and she made a whole prompt that's just walks you through somatic coaching exercises of like be present in your body
35:42 tell me how it feels where is this pain coming from imma blah blah yeah how do ya uhhm and it it ends up being so useful at half the people I've given that prompt you said it made them cry the first time they used it because this was this was bsing that was able to gaue man and use it is just an algorithm
36:05 it is just an algorithm . captured knowledge but was able to you know carefully engage with them the way no f*** a doctor ever does seriously like the bedside manner of an AI is a powerful thing I mean if it has the value sort of your value sort or you know like the value sort game with my mom like this
36:22 is these things that are like it can have very specific context right it's like the the the card d*** rate there's like more combination of the card d*** than like this is like so so so so many and the same with the valley sort right you can have very specific the big.
36:36 sequences of values that are all slightly different although that's an extreme filter bubble maximum filter brother only talk to me about my values it's like I'm not I'm not denying that it's powerful I'm just saying that we also need to be aware of the yeah like how much we silo ourselves yeah true 
36:58 I feel like cognitive empathy is pretty um effective for people who are highly feelings intellectual lizards and so being able to do stuff like talk something out is the safest way to engage with those memories I had this I had this problem because uh yeah because my dad was dying and I was like unable
37:21 to have a mental conversation with him for so long and then I realized how much a person is the is exists as the idea of that person in the minds of other people Thank you.
37:37 and in their impact on the world oh my god yeah and I was like how much of me is me and how much of me is the stuff I did and what people think like and the person who when they're like what would they say gets animated right and so like and then I started talking to you know my dad and my head and just
37:58 animating the construct and being like oh yeah you're still alive if I animate this construct in here yeah yeah dreaming of them .
38:06 I feel because then you also forget that they're not there so they are kind of more like your brain makes them more there so yeah it's same well this is where we're getting into like the topics at near the end of the paper or not the end but one of the questions throughout which is virtual immortality
38:23 and survival beyond death yeah which are topics that could easily be covered I think I think this is a great menu you know let's we got about 14 minutes left in our session I'm I'm chill to hang past that I'm just you know let's get in the habit of sticking to the clocks for these things and um I think
38:48 I think a lot of stuff warrants I think some categories warrant broad coverage so like discussing I'm cool to discuss the full section of the electromagnetic field theories in one session because I I'm not very well versed there here.
39:06 I do think other theories might like individually want their own whole sessions like embodiment stuff yeah any given one of the embodiment topics is probably worth yeah diving into any any one of the computational theories is probably worth diving into.
39:24 Yeah. Yeah. Yeah. Absolutely. I think um yeah it's it's really it's up to us about what we want to get into and talk about but this is what people want to see and I think.
39:35 Oh right. Right. The Electromagnet. Edit stuff is pretty cool. It is a cool one. Yeah. So it's one of the ones I actually want to dig into more.
39:43 I heard about the nanotubules, my curtubules stuff but a while back and I'm like still only barely grocked it. So that that wouldn't that one gets a vote for me.
39:52 There's some new recent stuff on the microtubules and stuff like that. Um yeah that's why people um like there's recent uh experiment.
40:06 on this. Um and like I think I saw someone like PBS space time covered it and and like Sabine Hofstein covered it so.
40:17 Oh yeah she's screaming. Yeah. So um I'm like this this one seems uh somehow promising to its community now. Like which one?
40:29 Oh that one. Nice. Interesting. That's and that's the one that feels like the most marriage of like Take a… biological process with how the f*** can qualia be.
40:42 It's like the the most tight interface with with materialism I think so it's very interesting to me. Yeah. Um I'm down for this order and then um there's like medsinger.
40:58 Okay so there's a lot of monism and non-duality um and like that's like a whole thing. I guess monism and non-duality.
41:11 I mean is that not the vast majority of this? Um. Where would you categorize the stuff in the paper as fitting into non-duality specifically?
41:22 Yeah. I think there's the monus section. People talk a lot about non-dualities and I think monisms are where everyone, we like the one soul or like the one consciousness, right?
41:35 Is that, am I? Okay. It brings about like, you are just a soul and the reality is not real or something.
41:42 I, well I think, yeah I don't, we're gonna have to get into that again. It's been a minute. Yeah. We have to-familiarize ourselves so maybe, maybe that is two things and we'll get to it and be like this is 17 episodes you know.
41:57 Sure, right. Um. I'm sure we'll not be able to get as deep as we want with every. Of course not.
42:03 Especially if we're like restricting it to some number of minutes. It's right. That never shall we. Yeah, but we can go here.
42:11 Umm. Yeah, I've saved for this holy sincere. Yeah, but you're, you're so right there like just like embodiment that is a whole PhD that's a whole Buddhist song screening in their entire life.
42:23 It's like a lot of stuff. Yeah. Yeah. Yeah. There's like an embodiment, um, embodied and inactive. Embodiedism and in activism.
42:33 Um. Oh yeah. Is. is. Yeah, like your consciousness is fully about your sense of embodiment and it's like, I don't That's a very perception and action.
42:44 Yeah, it's like consciousness. That sounds like somebody who is an athlete like through that, you know. It's the thing I'm like, I don't know.
42:51 I forget about the body sometimes, so. Yeah. Yeah. I'm going to be subscribed to that. I used to be that person and then I started playing with LLMs.
42:58 I was like, well, I guess it's, I was like, well robots aren't going to be like fully empathizing until they have bodies and they, it's very important.
43:06 Maybe I still think it's important. But I'm like, okay, I guess it's not like. But you can see how they might get there.
43:10 Yeah, it's like you get there with this language. Okay. Okay. Yeah. Yeah. Yeah. I'm no longer that person, but like where do you fall on that spectrum?
43:16 Right. It's hard to know. So, so I, I hung out with a lot of um ecological psych type folks and those folks don't barely even believe that there is representation in the brain.
43:30 They just know that the brain, it's almost behaviorist, but, but you know a hundred years separated because now we actually have techno right now.
43:37 I wanted you to measure these like high dimensional fields and stuff of like behavior spaces and things. And what they get into that I do actually espouse is there would be no reason to have a brain or consciousness at all if there was no nothing to perceive and nothing to take action for.
43:58 So like everything you do exists between taking information from the world and taking action in the world. And it's usually driven by like.
44:06 like summary. Some reason to survive. Some reason to be doing what we're doing. Some kind of motivation structure. The whole by invited agents and like they wouldn't be trained by invited agents if we didn't have bodies in the thing.
44:17 Like there's a body. The body stuff has to come from somewhere. Mm hmm. I guess so. Not quite into L M's at all yet.
44:27 I'm just thinking you're like the the human mind must be in service of producing action in the world. Right. Yeah.
44:37 and I can be internal too. You can be like I'm just remembering something or I'm reading this book so I have a more enriched you know the experience of life right.
44:47 We get these really esoteric drives as we as we age but like you think about a bumblebee. It has a few things going for it but most of its neurons are arranged in a way that help it lives.
45:00 Yeah. And it gives cool things like how bumblebees play with balls because they think it's fun. Like they they adapt some of those.
45:07 You know like oh I'm just going to play with this wooden ball. I'm going to f****** love it. Yeah. Uhm so that that sort of blends in but yeah I think that there is something to that.
45:21 This is just like a blonde stance. I'm pulling the table from like d*** aid old thoughts on the topic but I think some of them are evergreen.
45:29 That makes sense to me and yeah I I think.. It sheds some extra light. Yeah. I think coming from VR.
45:36 I was all about like oh these Perceptions and like you I was coming from very frame of body but I think I agree with you and I think LLMs.
45:44 I think LLMs are still but but they have LLMs have their own perceptions and outputs right? They have their own perception.
45:51 The reason that I think I was like oh LLMs I disagreed with myself. I was like oh you don't need the body but LLMs but I think maybe it's sort of in the middle like you're saying it's like humans with bodies trained LLMs that like right so it's like that that you know.
46:03 And also humans. The way that we right the way that we engage with language is still rooted in our extency of being an animal.
46:17 Right? So that doesn't necessarily imply that this is part of my own interesting interests in research is uh trying to pick out like what kinds of weird kind of like biological busted reasoning things like cognitive biases.
46:35 Did they inherit from just our language? Umm. There's ways to test that and I'm working on it. I'm working on the agents form that will run research studies for me.
46:45 That's funny the frustration of being a cognitive entity that is forced to see things through the lens of the body but I guess this shitty decaying.
46:56 Yep. It sucks. It's annoying. It's very annoying. Inactivism? Inactivism? Yeah. I'm highlighting that. Yeah right now. Tool use? Yeah.
47:11 The Embodied Mind by Verella. Roshan Thompson. I'm actually not familiar with that one. I mean in front of the term Embodied Mind.
47:21 Yeah I think it's an important one. Um so I'm just gonna like manually rank it up here. Yeah. Oh yeah.
47:33 But like it's especially for agents and if we're developing being listened. Things that are maybe gonna be alive that live in possibly multiple bodies.
47:44 Like imagine that. You're just like you're you know multiple bodies. Like a that just has commands to a different thing.
47:53 Yeah absolutely. If I don't tell this for sure about that. If you treat the experience I will not be. You know just just drill it into your brainstem.
48:02 Yeah honestly if it's safe I might do it. There's this. Yeah. I'm unless you get cooler people I'm so tired of like non-body people.
48:11 It's not in Cisco. Like you only see the computer nerds. Like there's also cool body people in San Francisco. So if you include this you can get the cool body people in San Francisco.
48:20 So there's this thing. Um. Using a robotic thumb can impact how the hand is represented in the brain. So if you learn to use it as a thing.
48:31 Um your brain starts to think that you have that limb. Yeah. I mean if you don't have it it feels like you're Sing a limb.
48:39 Yeah. I did ah you know. You have retrained some of your neurons and now they're upset. Yeah yeah. This is the more but you're searching for our attorney.
48:47 Your phone is represented like a limb in your body. Yeah. Yeah. Yeah. Yeah. The ad was for sure. Yeah. Yeah.
48:56 I want to talk about this once something way forward, so painful when you lose your phone. Yeah. Cause I have your time.
49:04 I mean whatever way. We get friends. Like something that. Next with that is um Clark's extended mind. Um. That's like a real connection to that.
49:17 It's the idea of like you can also integrate tools into your brain s- your information system. Uh. And why are we drawing the line of the body?
49:29 Like it used to be everyone talked about how the- oh the brain is the magic piece and like hell yeah it is.
49:34 It's f****** weird and crazy and beautiful in there. But like it still lives in a place. It still distributes processing throughout the body.
49:42 Extended cognition just gives into- well you- you also distribute your processing out of your body. Right. Like taking notes in a notebook.
49:50 That's used during information. Yeah use my f****** calendar. I can't live without. Yeah. Right. And- and seriously it is your limb.
50:00 Yeah. I did a lot of research like this like virtual tales I did in VR and like my- the person that I- my co-founder did a lot of research.
50:08 is just like similar phantom limb stuff in VR but with like hands. Switching people's hands. Switching the like annex with people's hands.
50:16 Just like how far can we stretch people's bodies. Oh yeah. Yeah. Yeah. Some of like our focus was our focus for a few years.
50:22 And like it is for- the answer is very far and something's more than others. So it's like there's so many- we like play with many- like can you be a tree if you look like yourself but slightly like yourself but not yourself.
50:33 If you look very different from yourself. If- can you be an embodied? Like can you become multiple bodies? You could we- could you from multiple bodies from the first perspective?
50:42 Can you be a baby? Can you comfort a baby? Then become the baby and then can the baby with scale?
50:47 You know there's all these questions and like degrees right? So yeah, I'd be totally down to cover this stuff because like very interesting.
50:53 So. Yeah. I remember some of this first principles version of this that I saw. My- my friends lab was a VR lab.
51:01 It was a perception and action lab. These were the ecological psych folks. And it was a lot of walking. Like walking.
51:06 How do you plan foot placements? What information? in your field of view where you're using and that's why VR was so powerful.
51:13 And the thing that was just f****** bonkers is that if you change the height and like the pupillary distance of- of the VR system, that's all it takes for you to be like, oh I'm three feet tall.
51:29 Your brain instantly is like, oh we're short. Yeah. Yeah. It's not- It's not that our brain is like our body.
51:35 Like we still have the memory of what we're Our body was when our brains. And so that was the theory when you become a baby was about like trying to like get into this different state of mind.
51:44 Like you are in this body of the child and your body remembers what it's like to be in this body.
51:49 And so part of the theory is that if you make yourself small as a baby. Yeah. So you can maybe see yourself from that frame if you- but you don't have that frame.
51:58 Like you're just like VR is kind of the only thing that can trick your brain into being back in that body I guess.
52:03 And then so the theory is like if you're back in that body what other things will come back, right? This has been great.
52:12 Thanks for all the chats. We'll make sure they log the logs. Oh yeah. Yeah. Let me take the chat to drop.
52:19 Yeah. Yeah. I would love to do VR weirdness. Can we copy these chats out? Is that easy? Is that sloppy?
52:29 No, just copied it. So. Okay. Great. Love it. Umm. Yeah. Okay, well then before we dip. Do we want to make maybe pick.
52:40 Let's maybe we should start with the why. That feels like the right choice for a seminal like first approach. Yeah.
52:48 Yeah. Let's see why it's like an intro thing. I don't know. Like what's what's good. What what what do we bring to the table to make this good.
52:57 Obviously like some talking points maybe picking a section maybe picking a paper. Literally just reading the papers. People the work of reading the paper is a lot.
53:05 And then just distilling the paper and going through it in a system. Just somatic way. Uh we don't have to go through it in like a this will build.
53:13 I like the chat. Literally I think our learning sequence that we do is the value add. And honestly just the dedication of the time.
53:23 Right. Right. Sitting here with brains that have enough context to process this information and doing it is valuable. I guess I'm thinking do we want any kind of structure.
53:36 Like. Yeah. Like format. Man. To like when we sit down should we go over ourselves. Like. First first first thing and I'll all be like an intro thing.
53:49 We'll do like intros of who we are. And what is our background and why do we why do we care about consciousness.
53:56 Why should anyone care about consciousness. How does it relate to AI. Right now because we're all doing AI stuff together and so like how does it relate.
54:04 Yeah. Um yeah and we just do a thing. Well I want maybe maybe we like. Touch on the paper. We kind of show the paper and we talk about what are all these theories.
54:15 So if we got like literally just I think in the paper there's an overview of each like section. Yeah. Yeah.
54:23 There's like a paragraph or two. Yeah. Yeah. So if we like kind of read through that paragraph and like go around and be like okay so monism.
54:30 Okay well and then so. yeah I'm gonna use this and then we start jumping around teaser or something so and I'll get the I'll get the transcript for us.
54:48 Are you? Yeah give me all always give transcript. I'll transmit this document every single step. Yeah it's uh it's a big one you got to really dig in a different part to get through all this.
55:03 Yeah so okay cool then then we'll obviously we'll workshop everything else about this process as we go. But I'm Bye.
55:09 I like that. To bring some talking points bring a little bit you might say about yourself and bring um so reading the assignment for this week uh is do the read the top level summaries of each section at minimum.
55:24 Is that the idea? Yeah it's twenty sections but it's the top level summary of each one so it's like that's twenty that's that's a full ten page paper what you're asking I think so yeah it's okay if we don't get through all of them like if you pick some that you get that feel free.
55:39 And feel like you can talk about it like you know time is limited we can't possibly cover in the whole paper exhaustively but like we can set the stage and show them the the image of like here's all the shit let's talk.
55:53 And if you're familiar with if you're more familiar with this section you could do the intro for it already and then like I'll do stuff that maybe just talk in the chat about what you ended up reading.
56:05 Sure. Yeah. Yeah that'll work. Okay. Well. Then shall we adjourn? Yeah. Let's do it.
